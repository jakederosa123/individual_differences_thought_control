{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/pl/active/banich/studies/Relevantstudies/abcd/data/clustering/analysis/')\n",
    "sys.path.append('/pl/active/banich/studies/Relevantstudies/abcd/env/lib/python3.7/site-packages')\n",
    "\n",
    "from functions import *\n",
    "import shap\n",
    "import xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from matplotlib import colors as plt_colors\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from igraph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_subid = pd.read_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/gradients/subj/matched_subid.csv')\n",
    "matched_subid.columns = ['sub', 'SubID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the pattern to match files\n",
    "pattern = '/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/gradients/subj/sub*_sm_vector/sub*_sm_vector_*_all_ops.csv'\n",
    "\n",
    "# Use glob to find all files that match the pattern\n",
    "file_list = sorted(glob.glob(pattern))\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "for file in file_list:\n",
    "    # Extract subject ID from the file path\n",
    "    subject_id = re.search(r'sub(\\d+)_', file).group(1)\n",
    "    \n",
    "    # Extract the part of the filename before '_all_ops'\n",
    "    grad = re.search(r'_(g\\d+)_all_ops', file).group(1)\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Add the subject ID as a new column\n",
    "    df['SubID'] = subject_id\n",
    "    \n",
    "    # Add the 'grad' as a new column\n",
    "    df['grad'] = grad\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all DataFrames into one, if necessary\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Now 'combined_df' contains all data with a 'SubID' and 'grad' column indicating the subject ID and the gradient respectively.\n",
    "# Adjusting the DataFrame by dropping and reordering columns as required\n",
    "combined_df = combined_df.drop(['Unnamed: 0', 'sub'], axis=1, errors='ignore')  # errors='ignore' handles cases where these columns might not exist\n",
    "combined_df = combined_df[['index', 'SubID', 'maintain', 'replace', 'suppress', 'clear', 'grad']]\n",
    "\n",
    "# combined_df now includes the 'grad' column with the part of the filename you were interested in.\n",
    "\n",
    "combined_df_g1 = combined_df.query('grad == \"g1\"').drop('grad', axis=1).reset_index(drop=True)\n",
    "combined_df_g1.columns = ['index', 'SubID', 'maintain_g1', 'replace_g1', 'suppress_g1', 'clear_g1']\n",
    "\n",
    "combined_df_g2 = combined_df.query('grad == \"g2\"').drop('grad', axis=1).reset_index(drop=True)\n",
    "combined_df_g2.columns = ['index', 'SubID', 'maintain_g2', 'replace_g2', 'suppress_g2', 'clear_g2']\n",
    "\n",
    "combined_df_g3 = combined_df.query('grad == \"g3\"').drop('grad', axis=1).reset_index(drop=True)\n",
    "combined_df_g3.columns = ['index', 'SubID', 'maintain_g3', 'replace_g3', 'suppress_g3', 'clear_g3']\n",
    "\n",
    "combined_all = pd.concat([combined_df_g1, \n",
    "                          combined_df_g2.drop(['index', 'SubID'], axis=1), \n",
    "                          combined_df_g3.drop(['index', 'SubID'], axis=1)], axis=1)\n",
    "\n",
    "combined_all = combined_all[['index', 'SubID', 'maintain_g1', 'maintain_g2', 'maintain_g3', 'replace_g1', 'replace_g2', 'replace_g3', \n",
    "              'suppress_g1', 'suppress_g2', 'suppress_g3', 'clear_g1', 'clear_g2', 'clear_g3']]\n",
    "\n",
    "wm_networks = pd.read_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/rest/rest_gradients/wm_networks.csv')\n",
    "wm_networks = wm_networks.reset_index()\n",
    "\n",
    "combined_all = pd.merge(wm_networks, combined_all, on='index').sort_values(['SubID', 'index'])\n",
    "\n",
    "combined_all.SubID = combined_all.SubID.astype(int)\n",
    "\n",
    "combined_all = (pd.merge(matched_subid, combined_all, on='SubID')\n",
    "               .drop('SubID', axis=1).rename({'sub':'SubID'}, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sub_ranges(data, sub):\n",
    "    \n",
    "    range_cols = ['maintain_g1', 'maintain_g2', 'maintain_g3', 'replace_g1', 'replace_g2',\n",
    "           'replace_g3', 'suppress_g1', 'suppress_g2', 'suppress_g3', 'clear_g1',\n",
    "           'clear_g2', 'clear_g3']\n",
    "\n",
    "    def range_dif(data, sub, col):\n",
    "\n",
    "        data = data.query('SubID == @sub')\n",
    "\n",
    "        dif = data[col].max() - data[col].min()\n",
    "\n",
    "        return dif \n",
    "\n",
    "    sub_ranges = []\n",
    "    for i in range_cols:\n",
    "        sub_ranges.append(range_dif(data, sub, i))\n",
    "\n",
    "    sub_range_df = pd.DataFrame(sub_ranges).T\n",
    "    sub_range_df.columns = range_cols\n",
    "    sub_range_df = sub_range_df.assign(SubID = sub)\n",
    "    sub_range_df = sub_range_df[['SubID'] + range_cols]\n",
    "    \n",
    "    return sub_range_df\n",
    "\n",
    "sub_ranges = []\n",
    "for i in combined_all.SubID.unique():\n",
    "    sub_ranges.append(process_sub_ranges(combined_all, i))\n",
    "    \n",
    "sub_range_df = pd.concat(sub_ranges)\n",
    "\n",
    "sub_range_df.to_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/gradients/dispersion_data/derosa_task_gradient_range.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_data = pd.read_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/gradients/analysis/ClearMem_Z_Average.csv')\n",
    "z_data = z_data[['SubID', 'z_ave', 'PSWQ_total', 'WBSI_total', 'RRS_total', 'RRS_depression', 'RRS_brooding', 'RRS_reflection']]\n",
    "z_data = z_data.dropna()\n",
    "\n",
    "from scipy.stats import zscore\n",
    "z_data['br_z_ave'] = z_data['z_ave']\n",
    "z_data.drop('z_ave', axis=1, inplace=True)\n",
    "z_data['thought_problems'] = (zscore(z_data['PSWQ_total']) + zscore(z_data['WBSI_total']) + zscore(z_data['RRS_brooding']))/3\n",
    "z_data['b_z_ave'] = (zscore(z_data['PSWQ_total']) + zscore(z_data['WBSI_total']) + zscore(z_data['RRS_brooding']) + zscore(z_data['RRS_reflection']) + zscore(z_data['RRS_depression']))/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_range_z = pd.merge(z_data, sub_range_df, on='SubID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_range_z = sub_range_z[['SubID', 'thought_problems',\n",
    "       'maintain_g1', 'maintain_g2', 'maintain_g3', 'replace_g1', 'replace_g2',\n",
    "       'replace_g3', 'suppress_g1', 'suppress_g2', 'suppress_g3', 'clear_g1',\n",
    "       'clear_g2', 'clear_g3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_range = sub_range_z.filter(regex = 'g1').T.mean()\n",
    "g2_range = sub_range_z.filter(regex = 'g2').T.mean()\n",
    "g3_range = sub_range_z.filter(regex = 'g3').T.mean()\n",
    "\n",
    "mean_ranges = pd.concat([g1_range, g2_range, g3_range], axis=1)\n",
    "mean_ranges.columns = ['g1_range', 'g2_range', 'g3_range']\n",
    "\n",
    "mean_ranges['SubID'] = sub_range_z['SubID']\n",
    "\n",
    "sub_range_z = pd.merge(sub_range_z, mean_ranges, on='SubID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(data, target, y_vars, interaction=None):\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    \n",
    "    if interaction is not None:\n",
    "        # Creating the formula with interaction terms if there are multiple y_vars\n",
    "        if len(y_vars) > 1:\n",
    "            joined_vars = ' * '.join(y_vars)\n",
    "        else:\n",
    "            joined_vars = y_vars[0]\n",
    "        \n",
    "        new_y_vars = [joined_vars]\n",
    "        formula = f'{target[0]} ~ {joined_vars}'\n",
    "\n",
    "    else:\n",
    "        joined_vars = ' + '.join(y_vars)\n",
    "        new_y_vars = [joined_vars]\n",
    "        formula = f'{target[0]} ~ {joined_vars}'\n",
    "\n",
    "    # Fit the regression model using the formula\n",
    "    model = smf.ols(formula=formula, data=data).fit()\n",
    "\n",
    "    # Print the full regression output\n",
    "    summary = model.summary()\n",
    "\n",
    "    var = pd.DataFrame(summary.tables[0].data).iloc[0, 1]\n",
    "\n",
    "    table1 = pd.DataFrame(summary.tables[0].data).iloc[:4, 3:].T.assign(var=var)\n",
    "    table1.columns = ['r2', 'adjr2', 'fstat', 'pval', 'var']\n",
    "    table1 = table1[['var', 'r2', 'adjr2', 'fstat', 'pval']]\n",
    "\n",
    "    table2_cols = pd.DataFrame(summary.tables[1].data).loc[0].to_list() + ['var']\n",
    "    table2_cols[0] = 'parameter'\n",
    "    table2 = pd.DataFrame(summary.tables[1].data).iloc[1:].assign(var=var)\n",
    "    table2.columns = table2_cols\n",
    "    table2 = table2[['var', 'parameter', 'coef', 'std err', 't', 'P>|t|']]\n",
    "\n",
    "    df = pd.merge(table1, table2, how='outer', left_on='var', right_on='parameter')\n",
    "\n",
    "    # Combine 'var_x' and 'var_y' into a new column 'var'\n",
    "    df['var'] = df['var_x'].fillna(df['var_y'])\n",
    "\n",
    "    # Drop the original 'var_x' and 'var_y' columns\n",
    "    df.drop(columns=['var_x', 'var_y'], inplace=True)\n",
    "\n",
    "    # Reorder columns to place 'var' at the front\n",
    "    cols = ['var'] + [col for col in df.columns if col != 'var']\n",
    "    df = df[cols]\n",
    "    df = df.assign(formula=formula)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def regression_function(data, variable_list, interaction):\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    # Given list\n",
    "    variables = variable_list\n",
    "    targets = [['thought_problems']]\n",
    "\n",
    "    # Create a list to hold all combinations\n",
    "    all_combinations = []\n",
    "\n",
    "    # Generate combinations for each length from 1 to the length of the list\n",
    "    for r in range(1, len(variables) + 1):\n",
    "        combinations = list(itertools.combinations(variables, r))\n",
    "        all_combinations.extend(combinations)\n",
    "\n",
    "    # Convert each tuple to a list\n",
    "    list_combinations = [list(item) for item in all_combinations]\n",
    "\n",
    "    regression_combinations = []\n",
    "    for i in targets:\n",
    "        for j in list_combinations:\n",
    "            regression_combinations.append(run_regression(data, i, j, interaction))\n",
    "\n",
    "    output_regressions = pd.concat(regression_combinations)\n",
    "\n",
    "    # List of columns to convert\n",
    "    columns_to_convert = ['r2', 'adjr2', 'fstat', 'pval', 'coef', 'std err', 't', 'P>|t|']\n",
    "\n",
    "    # Convert each specified column to numeric, handling non-numeric values by converting them to NaN\n",
    "    for column in columns_to_convert:\n",
    "        output_regressions[column] = pd.to_numeric(output_regressions[column], errors='coerce')\n",
    "\n",
    "    return output_regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.append('/pl/active/banich/studies/Relevantstudies/abcd/env/lib/python3.7/site-packages')\n",
    "sys.path.append('/pl/active/banich/studies/Clearvale/jake_scripts/Amy_flywheel_scripts/')\n",
    "\n",
    "import sys \n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "def run_regression(data, target, y_var, interaction=None):\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    \n",
    "    if interaction is not None:\n",
    "        # Creating the formula with interaction terms if specified\n",
    "        formula = f'{target[0]} ~ {y_var} * {interaction}'\n",
    "    else:\n",
    "        formula = f'{target[0]} ~ {y_var}'\n",
    "\n",
    "    # Fit the regression model using the formula\n",
    "    model = smf.ols(formula=formula, data=data).fit()\n",
    "\n",
    "    # Print the full regression output\n",
    "    summary = model.summary()\n",
    "\n",
    "    var = pd.DataFrame(summary.tables[0].data).iloc[0, 1]\n",
    "\n",
    "    table1 = pd.DataFrame(summary.tables[0].data).iloc[:4, 3:].T.assign(var=var)\n",
    "    table1.columns = ['r2', 'adjr2', 'fstat', 'pval', 'var']\n",
    "    table1 = table1[['var', 'r2', 'adjr2', 'fstat', 'pval']]\n",
    "\n",
    "    table2_cols = pd.DataFrame(summary.tables[1].data).loc[0].to_list() + ['var']\n",
    "    table2_cols[0] = 'parameter'\n",
    "    table2 = pd.DataFrame(summary.tables[1].data).iloc[1:].assign(var=var)\n",
    "    table2.columns = table2_cols\n",
    "    table2 = table2[['var', 'parameter', 'coef', 'std err', 't', 'P>|t|']]\n",
    "\n",
    "    df = pd.merge(table1, table2, how='outer', left_on='var', right_on='parameter')\n",
    "\n",
    "    # Combine 'var_x' and 'var_y' into a new column 'var'\n",
    "    df['var'] = df['var_x'].fillna(df['var_y'])\n",
    "\n",
    "    # Drop the original 'var_x' and 'var_y' columns\n",
    "    df.drop(columns=['var_x', 'var_y'], inplace=True)\n",
    "\n",
    "    # Reorder columns to place 'var' at the front\n",
    "    cols = ['var'] + [col for col in df.columns if col != 'var']\n",
    "    df = df[cols]\n",
    "    df = df.assign(formula=formula)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def regression_function(data, variable_list, interaction):\n",
    "    import pandas as pd\n",
    "\n",
    "    targets = [['thought_problems']]\n",
    "\n",
    "    regression_results = []\n",
    "    for target in targets:\n",
    "        for variable in variable_list:\n",
    "            regression_results.append(run_regression(data, target, variable, interaction))\n",
    "\n",
    "    output_regressions = pd.concat(regression_results)\n",
    "\n",
    "    # List of columns to convert\n",
    "    columns_to_convert = ['r2', 'adjr2', 'fstat', 'pval', 'coef', 'std err', 't', 'P>|t|']\n",
    "\n",
    "    # Convert each specified column to numeric, handling non-numeric values by converting them to NaN\n",
    "    for column in columns_to_convert:\n",
    "        output_regressions[column] = pd.to_numeric(output_regressions[column], errors='coerce')\n",
    "\n",
    "    return output_regressions#[['var', 'r2', 'adjr2', 'fstat', 'pval', 'formula']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_range_z = sub_range_z[['SubID', 'thought_problems',\n",
    "       'maintain_g1', 'maintain_g2', 'maintain_g3', 'replace_g1', 'replace_g2',\n",
    "       'replace_g3', 'suppress_g1', 'suppress_g2', 'suppress_g3', 'clear_g1',\n",
    "       'clear_g2', 'clear_g3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = ['maintain_g1', 'maintain_g2', 'maintain_g3', 'replace_g1', 'replace_g2',\n",
    "       'replace_g3', 'suppress_g1', 'suppress_g2', 'suppress_g3', 'clear_g1',\n",
    "       'clear_g2', 'clear_g3']\n",
    "\n",
    "range_regs = regression_function(sub_range_z, test_cols, interaction=None).query('pval < .05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>r2</th>\n",
       "      <th>adjr2</th>\n",
       "      <th>fstat</th>\n",
       "      <th>pval</th>\n",
       "      <th>parameter</th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [var, r2, adjr2, fstat, pval, parameter, coef, std err, t, P>|t|, formula]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_regs.sort_values('fstat', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = ['g1_range', 'g2_range', 'g3_range']\n",
    "\n",
    "all_range_regs = regression_function(sub_range_z, test_cols, interaction=None)#.query('pval < .05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>r2</th>\n",
       "      <th>adjr2</th>\n",
       "      <th>fstat</th>\n",
       "      <th>pval</th>\n",
       "      <th>parameter</th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.05360</td>\n",
       "      <td>0.818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought_problems ~ g1_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-0.2623</td>\n",
       "      <td>1.246</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>0.834</td>\n",
       "      <td>thought_problems ~ g1_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g1_range</td>\n",
       "      <td>1.5563</td>\n",
       "      <td>6.722</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.818</td>\n",
       "      <td>thought_problems ~ g1_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.15660</td>\n",
       "      <td>0.694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought_problems ~ g2_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>-0.3692</td>\n",
       "      <td>1.003</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.714</td>\n",
       "      <td>thought_problems ~ g2_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g2_range</td>\n",
       "      <td>2.0750</td>\n",
       "      <td>5.244</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.694</td>\n",
       "      <td>thought_problems ~ g2_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.00779</td>\n",
       "      <td>0.930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought_problems ~ g3_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>1.126</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.913</td>\n",
       "      <td>thought_problems ~ g3_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought_problems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g3_range</td>\n",
       "      <td>-0.6515</td>\n",
       "      <td>7.382</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.930</td>\n",
       "      <td>thought_problems ~ g3_range</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                var     r2  adjr2    fstat   pval  parameter    coef  std err  \\\n",
       "0  thought_problems  0.001 -0.021  0.05360  0.818        NaN     NaN      NaN   \n",
       "1  thought_problems    NaN    NaN      NaN    NaN  Intercept -0.2623    1.246   \n",
       "2  thought_problems    NaN    NaN      NaN    NaN   g1_range  1.5563    6.722   \n",
       "0  thought_problems  0.003 -0.018  0.15660  0.694        NaN     NaN      NaN   \n",
       "1  thought_problems    NaN    NaN      NaN    NaN  Intercept -0.3692    1.003   \n",
       "2  thought_problems    NaN    NaN      NaN    NaN   g2_range  2.0750    5.244   \n",
       "0  thought_problems  0.000 -0.022  0.00779  0.930        NaN     NaN      NaN   \n",
       "1  thought_problems    NaN    NaN      NaN    NaN  Intercept  0.1236    1.126   \n",
       "2  thought_problems    NaN    NaN      NaN    NaN   g3_range -0.6515    7.382   \n",
       "\n",
       "       t  P>|t|                      formula  \n",
       "0    NaN    NaN  thought_problems ~ g1_range  \n",
       "1 -0.211  0.834  thought_problems ~ g1_range  \n",
       "2  0.232  0.818  thought_problems ~ g1_range  \n",
       "0    NaN    NaN  thought_problems ~ g2_range  \n",
       "1 -0.368  0.714  thought_problems ~ g2_range  \n",
       "2  0.396  0.694  thought_problems ~ g2_range  \n",
       "0    NaN    NaN  thought_problems ~ g3_range  \n",
       "1  0.110  0.913  thought_problems ~ g3_range  \n",
       "2 -0.088  0.930  thought_problems ~ g3_range  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_range_regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
