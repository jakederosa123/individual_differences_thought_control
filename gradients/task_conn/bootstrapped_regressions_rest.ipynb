{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/pl/active/banich/studies/Relevantstudies/abcd/env/lib/python3.7/site-packages')\n",
    "sys.path.append('/pl/active/banich/studies/Clearvale/jake_scripts/Amy_flywheel_scripts/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_z = pd.read_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/rest/rest_all_metrics_z.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "# Assuming sub_data is your DataFrame and filtered_data is already defined\n",
    "# filtered_data = sub_data.filter(regex='disp')\n",
    "# Filter columns based on regex\n",
    "filtered_data = all_metrics_z.iloc[:, 1:]\n",
    "\n",
    "# Apply Yeo-Johnson transformation\n",
    "# Note: power_transform returns a numpy array, so we need to convert it back to a DataFrame\n",
    "yeo_johnson_transformed_data = pd.DataFrame(power_transform(filtered_data, method='yeo-johnson'), columns=filtered_data.columns)\n",
    "\n",
    "#yeo_johnson_transformed_data\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Perform the Shapiro-Wilk test for normality\n",
    "shapiro_test = stats.shapiro(yeo_johnson_transformed_data)\n",
    "\n",
    "print(f\"Shapiro-Wilk Test statistic: {shapiro_test.statistic}, p-value: {shapiro_test.pvalue}\")\n",
    "\n",
    "# Interpretation of the result\n",
    "if shapiro_test.pvalue > 0.05:\n",
    "    print(\"The data is likely normal (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"The data is likely not normal (reject H0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_z_yeo = pd.concat([all_metrics_z[['SubID']], yeo_johnson_transformed_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(data, target, y_vars, interaction=None):\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "\n",
    "    if interaction is not None:\n",
    "        # Creating the formula with interaction terms if there are multiple y_vars\n",
    "        if len(y_vars) > 1:\n",
    "            joined_vars = ' * '.join(y_vars)\n",
    "        else:\n",
    "            joined_vars = y_vars[0]\n",
    "        \n",
    "        new_y_vars = [joined_vars]\n",
    "        formula = f'{target[0]} ~ {joined_vars}'\n",
    "\n",
    "    else:\n",
    "        joined_vars = ' + '.join(y_vars)\n",
    "        new_y_vars = [joined_vars]\n",
    "        formula = f'{target[0]} ~ {joined_vars}'\n",
    "\n",
    "    # Fit the regression model using the formula\n",
    "    model = smf.ols(formula=formula, data=data).fit()\n",
    "\n",
    "    # Print the full regression output\n",
    "    summary = model.summary()\n",
    "\n",
    "    var = pd.DataFrame(summary.tables[0].data).iloc[0, 1]\n",
    "\n",
    "    table1 = pd.DataFrame(summary.tables[0].data).iloc[:4, 3:].T.assign(var=var)\n",
    "    table1.columns = ['r2', 'adjr2', 'fstat', 'pval', 'var']\n",
    "    table1 = table1[['var', 'r2', 'adjr2', 'fstat', 'pval']]\n",
    "\n",
    "    table2_cols = pd.DataFrame(summary.tables[1].data).loc[0].to_list() + ['var']\n",
    "    table2_cols[0] = 'parameter'\n",
    "    table2 = pd.DataFrame(summary.tables[1].data).iloc[1:].assign(var=var)\n",
    "    table2.columns = table2_cols\n",
    "    table2 = table2[['var', 'parameter', 'coef', 'std err', 't', 'P>|t|']]\n",
    "\n",
    "    df = pd.merge(table1, table2, how='outer', left_on='var', right_on='parameter')\n",
    "\n",
    "    # Combine 'var_x' and 'var_y' into a new column 'var'\n",
    "    df['var'] = df['var_x'].fillna(df['var_y'])\n",
    "\n",
    "    # Drop the original 'var_x' and 'var_y' columns\n",
    "    df.drop(columns=['var_x', 'var_y'], inplace=True)\n",
    "\n",
    "    # Reorder columns to place 'var' at the front\n",
    "    cols = ['var'] + [col for col in df.columns if col != 'var']\n",
    "    df = df[cols]\n",
    "    df = df.assign(formula=formula)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def regression_function(data, variable_list, interaction):\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    # Given list\n",
    "    variables = variable_list\n",
    "    targets = [['brd_z_ave']]\n",
    "\n",
    "    # Create a list to hold all combinations\n",
    "    all_combinations = []\n",
    "\n",
    "    # Generate combinations for each length from 1 to the length of the list\n",
    "    for r in range(1, len(variables) + 1):\n",
    "        combinations = list(itertools.combinations(variables, r))\n",
    "        all_combinations.extend(combinations)\n",
    "\n",
    "    # Convert each tuple to a list\n",
    "    list_combinations = [list(item) for item in all_combinations]\n",
    "\n",
    "    regression_combinations = []\n",
    "    for i in targets:\n",
    "        for j in list_combinations:\n",
    "            regression_combinations.append(run_regression(data, i, j, interaction))\n",
    "\n",
    "    output_regressions = pd.concat(regression_combinations)\n",
    "\n",
    "    # List of columns to convert\n",
    "    columns_to_convert = ['r2', 'adjr2', 'fstat', 'pval', 'coef', 'std err', 't', 'P>|t|']\n",
    "\n",
    "    # Convert each specified column to numeric, handling non-numeric values by converting them to NaN\n",
    "    for column in columns_to_convert:\n",
    "        output_regressions[column] = pd.to_numeric(output_regressions[column], errors='coerce')\n",
    "\n",
    "    return output_regressions\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def process_sample(data, columns):\n",
    "    # Sample with replacement\n",
    "    sample = data.sample(n=len(data), replace=True)\n",
    "    # Run the regression function\n",
    "    result = regression_function(sample, columns, interaction=None)\n",
    "    return result\n",
    "\n",
    "def bootstrap_regression_parallel(data, columns, n_iterations=1000):\n",
    "    results = []\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # Submit all tasks to the executor\n",
    "        futures = [executor.submit(process_sample, data, columns) for _ in range(n_iterations)]\n",
    "        \n",
    "        # As each future completes, gather results\n",
    "        for future in as_completed(futures):\n",
    "            results.append(future.result())\n",
    "    \n",
    "    # Concatenate all results into a single DataFrame\n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = ['vn_smn_disp', 'fpcn_dmn_disp', 'smn_fpcn_disp',\n",
    "       'vn_fpcn_disp', 'smn_dmn_disp', 'vn_dmn_disp', 'vn_disp', 'smn_disp',\n",
    "       'fpcn_disp', 'dmn_disp', 'vn_ecc', 'smn_ecc', 'fpcn_ecc', 'dmn_ecc',\n",
    "       'vn_eigcent', 'smn_eigcent', 'fpcn_eigcent', 'dmn_eigcent', 'vn_mod',\n",
    "       'smn_mod', 'fpcn_mod', 'dmn_mod', 'rest_within_disp',\n",
    "       'rest_across_disp', 'rest_ecc', 'rest_eigcent', 'rest_mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_regression(data, columns, n_iterations=1000):\n",
    "    # Store results in a list of DataFrames\n",
    "    \n",
    "    global regression_function\n",
    "    \n",
    "    results = []\n",
    "    # Perform bootstrapping\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        # Sample with replacement\n",
    "        sample = data.sample(n=len(data), replace=True)\n",
    "\n",
    "        # Run the regression function\n",
    "        result = regression_function(sample, columns, interaction=None)\n",
    "        print\n",
    "        # Append the result to the list\n",
    "        results.append(result)\n",
    "    \n",
    "    # Concatenate all results into a single DataFrame\n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "\n",
    "test_list = ['vn_smn_disp', 'fpcn_dmn_disp', 'smn_fpcn_disp',\n",
    "       'vn_fpcn_disp', 'smn_dmn_disp', 'vn_dmn_disp', 'vn_disp', 'smn_disp',\n",
    "       'fpcn_disp', 'dmn_disp', 'vn_ecc', 'smn_ecc', 'fpcn_ecc', 'dmn_ecc',\n",
    "       'rest_within_disp','rest_across_disp', 'rest_ecc', 'rest_eigcent']\n",
    "\n",
    "# Call the bootstrap function with your dataset, regression function, and the list of all features\n",
    "bootstrapped_results = bootstrap_regression(all_metrics_z, test_list, n_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_results.to_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/rest/rest_regressions/bootstrap_regressions/bootstrap_regressions/boot_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_results = pd.read_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/rest/rest_regressions/bootstrap_regressions/bootstrap_regressions/boot_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Assuming bootstrapped_results is already loaded as a DataFrame\n",
    "# First, let's group by 'formula' and calculate the mean and standard deviation of 'pval'\n",
    "# Assuming 'fstat' and 'adjr2' are columns in bootstrapped_results DataFrame\n",
    "# Group by 'formula' and calculate the mean and standard deviation of 'pval', and mean of 'fstat' and 'adjr2'\n",
    "stats = bootstrapped_results.groupby('formula').agg({\n",
    "    'pval': ['mean', 'std'],\n",
    "    'fstat': ['mean', 'std'],\n",
    "    'adjr2': ['mean', 'std']\n",
    "})\n",
    "\n",
    "# Rename columns for clarity\n",
    "stats.columns = ['mean_pval', 'std_pval', 'mean_fstat', 'std_fstat', 'mean_adjr2', 'std_adjr2']\n",
    "\n",
    "# Sort the formulas first by mean_pval in ascending order (lower means better),\n",
    "# and then by std_pval in ascending order (lower variability is better)\n",
    "sorted_stats = stats.sort_values(by=['mean_pval', 'std_pval'])\n",
    "\n",
    "# Now, select the top 10 formulas\n",
    "top_10_formulas = sorted_stats.head(10).reset_index()\n",
    "\n",
    "top_10_formulas.formula = top_10_formulas.formula.str.replace('brd_z_ave ~', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_formulas = top_10_formulas.formula.to_list()\n",
    "filter_formulas = ['brd_z_ave ~' + item for item in filter_formulas]\n",
    "\n",
    "top_10_boot_adjr2 = bootstrapped_results.query('formula in @filter_formulas')[['adjr2', 'formula']].dropna()\n",
    "top_10_boot_pval = bootstrapped_results.query('formula in @filter_formulas')[['pval', 'formula']].dropna()\n",
    "top_10_boot_fstat = bootstrapped_results.query('formula in @filter_formulas')[['fstat', 'formula']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_boot_stats = pd.concat([top_10_boot_adjr2, top_10_boot_fstat, top_10_boot_pval], axis=1).iloc[:, [1,0,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_formulas = ['brd_z_ave ~' + item for item in top_10_formulas.head(5).formula.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Melting the DataFrame to make it suitable for seaborn's factorplot\n",
    "df_melted = top_10_boot_stats.melt(id_vars=['formula'], value_vars=['adjr2', 'pval', 'fstat'],\n",
    "                                   var_name='Metric', value_name='Value')\n",
    "\n",
    "stat_names = {\n",
    "'pval': 'p',\n",
    "'fstat': 'F',\n",
    "'adjr2': 'adj. r2'\n",
    "}\n",
    "\n",
    "df_melted.Metric = df_melted.Metric.map(stat_names)\n",
    "\n",
    "df_melted = df_melted.query('formula in @top_5_formulas')\n",
    "\n",
    "df_melted.formula = df_melted.formula.str.replace('brd_z_ave ~', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating the facet grid plot without a legend\n",
    "g = sns.catplot(x='Value', y='formula', hue='Metric', data=df_melted, kind='point', \n",
    "                height=5, aspect=1, join=False, palette='viridis', col='Metric', \n",
    "                sharex=False, legend=False, col_wrap=1)\n",
    "\n",
    "# Enhancing the plot\n",
    "g.set_axis_labels(\"Value\", \"Formula\")\n",
    "# Adjust tick rotation if necessary\n",
    "#plt.xticks(rotation=45)\n",
    "\n",
    "# Removing \"Metric = \" from the plot titles\n",
    "for ax in g.axes.flat:\n",
    "    if ax.get_title():\n",
    "        ax.set_title(ax.get_title().split(' = ')[-1])\n",
    "\n",
    "# Set up the figure's layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define save path\n",
    "save_path = '/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/rest/rest_regressions/bootstrap_regressions/figures/top_5_formulas.png'\n",
    "\n",
    "# Use the FacetGrid's savefig method\n",
    "g.savefig(save_path, dpi=300, bbox_inches='tight')  # bbox_inches='tight' can help with cutting issues\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_10_formulas.to_csv('/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/gradients/analysis/operation_regressions/bootstrap_regressions/top_10_formulas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vars = ['dmn_mean', 'vn_mean_ecc', 'dmn_mean_ecc', 'global_acc', 'fpcn_dmn_mean']\n",
    "\n",
    "run_regression(sub_disp_ecc_acc_ev_means, ['brd_z_ave'], reg_vars, interaction=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(formula='brd_z_ave ~ dmn_mean + vn_mean_ecc + dmn_mean_ecc + global_acc + fpcn_dmn_mean', \n",
    "                data=sub_disp_ecc_acc_ev_means).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_disp_ecc_acc_ev_means[['brd_z_ave', 'dmn_mean', 'vn_mean_ecc', 'dmn_mean_ecc', 'global_acc', 'fpcn_dmn_mean']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_disp_ecc_acc_ev_means[['brd_z_ave', 'dmn_mean', 'fpcn_mean', 'vn_mean', 'smn_mean']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_plots(data, x_vars, yvar, color, title, formula_title, save=None):\n",
    "\n",
    "    import pandas as pd\n",
    "    #import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Set the entire script to use Arial\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    \n",
    "    joined_vars = ' + '.join(x_vars)\n",
    "    new_y_vars = [joined_vars]\n",
    "    formula = f'{yvar[0]} ~ {joined_vars}'\n",
    "\n",
    "    # Fit the regression model using the formula\n",
    "    model = smf.ols(formula=formula, data=data).fit()\n",
    "\n",
    "    # Prepare the design matrix X with multiple x_vars\n",
    "    #X = sm.add_constant(data[x_vars])  # Adding a constant\n",
    "    #model = sm.OLS(data[yvar], X).fit()\n",
    "    data['Predicted'] = model.predict()  # Store the predicted values\n",
    "\n",
    "    # Adjust figure size\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Increased figure size\n",
    "\n",
    "    # Scatter plot with regression line, ensuring CI is shown\n",
    "    sns.set_theme(style=\"white\")\n",
    "\n",
    "    # Scatter plot with regression line modifications\n",
    "    sns.regplot(y='Predicted', x=f'{yvar[0]}', data=data, ci=95,\n",
    "                color=color, scatter_kws={'s': 40, 'alpha': 0.6}, truncate=False, ax=ax,\n",
    "                line_kws={'linewidth': 2.5, 'alpha': 0.4})  # Set line width and transparency\n",
    "\n",
    "    sns.regplot(y='Predicted', x=f'{yvar[0]}', data=data, fit_reg=False,\n",
    "                color='white', scatter_kws={'s': 20, 'alpha': .5}, truncate=False, ax=ax)\n",
    "\n",
    "\n",
    "   # Set axis labels\n",
    "    ax.set_xlabel('Thought Problems', fontsize=15)\n",
    "    ax.set_ylabel('Predicted', fontsize=15)\n",
    "\n",
    "    # Set title using text for precise control\n",
    "    ax.text(.02, 1.07, title, transform=ax.transAxes, fontsize=15, fontweight='bold', verticalalignment='top')\n",
    "\n",
    "    # Adding subtitle with F-statistic and p-value using text annotation, with 'p' in italic\n",
    "    subtitle = f\"F={model.fvalue:.3f}, \"\n",
    "    ax.text(.02, 1, subtitle, transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "    ax.text(.02 + ax.transAxes.inverted().transform(ax.transData.transform((-1.13, 0)))[0], 1, \"p\", transform=ax.transAxes, fontsize=14, verticalalignment='top', style='italic')\n",
    "    ax.text(.02 + ax.transAxes.inverted().transform(ax.transData.transform((-1.06, 0)))[0], 1, f\"={model.f_pvalue:.3f}\", transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "\n",
    "    ax.text(.02 + ax.transAxes.inverted().transform(ax.transData.transform((-.7, 0)))[0], 1, \", adj. r2\", transform=ax.transAxes, fontsize=14, verticalalignment='top', style='italic')\n",
    "    ax.text(.02 + ax.transAxes.inverted().transform(ax.transData.transform((-.31, 0)))[0], 1, f\"={model.rsquared_adj:.3f}\", transform=ax.transAxes, fontsize=14, verticalalignment='top')\n",
    "\n",
    "    # Adjust tick parameters for both axes\n",
    "    ax.tick_params(axis='both', labelsize=12)  # Increase tick label font size\n",
    "\n",
    "    # Remove top and right borders\n",
    "    sns.despine()\n",
    "\n",
    "      # Formula at the bottom\n",
    "    ax.text(0.45, -0.2, formula_title, transform=ax.transAxes, fontsize=10, ha='center', va='top')\n",
    "\n",
    "    # Adjust tick parameters for both axes\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    sns.despine()\n",
    "\n",
    "    # Manually adjust the subplot parameters\n",
    "    plt.subplots_adjust(left=0.15, right=0.95, top=0.85, bottom=0.25)  # Adjusted to make space for formula text\n",
    "\n",
    "\n",
    "    if save is not None:\n",
    "        save_path = f'/pl/active/banich/studies/wmem/fmri/operation_rsa/grp/gradients/analysis/operation_regressions/figures/{save}.png'\n",
    "        plt.savefig(save_path, dpi=300,  bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_plots(sub_disp_ecc_acc_ev_means, reg_vars, ['brd_z_ave'], '#a8009d', 'Best Fitting Metrics Predicting Thought Problems', \n",
    "          'Thought Problems ~ dmn_mean + vn_mean_ecc + dmn_mean_ecc + clear_acc + fpcn_dmn_mean', save='top_formula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script bootstrapped_regressions.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
